{"cells": [{"cell_type": "code", "execution_count": 1, "id": "89e34f03-48b6-47e5-8a08-b9d8215f3cdf", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import split, explode\nfrom pyspark.sql.types import IntegerType\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nspark = SparkSession.builder.appName(\"More models\").getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "a89f614c-1205-4741-abb3-021fe6eea65d", "metadata": {}, "outputs": [], "source": "# Import required libraries\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator"}, {"cell_type": "code", "execution_count": 3, "id": "aabbad8f-b00a-4232-9323-e67d6aa6af95", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# load AZ data\nbucket_dir=\"gs://pstat135-voter-file/VM2Uniform/\"\ndf = spark.read.parquet(bucket_dir + 'VM2Uniform--AZ--2021-05-20')\n\n# Read MA data\ndfma = spark.read.parquet(bucket_dir + 'VM2Uniform--MA--2021-01-19')\n\n# load ND data\ndfnd = spark.read.parquet(bucket_dir + 'VM2Uniform--ND--2021-03-18')"}, {"cell_type": "code", "execution_count": 24, "id": "b236582a-136b-4d7c-af96-72dcd1efe67e", "metadata": {}, "outputs": [], "source": "# convert string columns to numeric \ndf = df.withColumn(\n    \"ElectionReturns_G18CountyTurnoutAllRegisteredVoters\", \n    regexp_replace(\n        \"ElectionReturns_G18CountyTurnoutAllRegisteredVoters\", \"%\", \"\"\n    ).cast(IntegerType())\n)\ndf = df.withColumn(\n    \"ElectionReturns_G14CountyTurnoutAllRegisteredVoters\", \n    regexp_replace(\n        \"ElectionReturns_G14CountyTurnoutAllRegisteredVoters\", \"%\", \"\"\n    ).cast(IntegerType())\n)\ndf = df.withColumn(\n    \"ElectionReturns_G08CountyTurnoutAllRegisteredVoters\", \n    regexp_replace(\n        \"ElectionReturns_G08CountyTurnoutAllRegisteredVoters\", \"%\", \"\"\n    ).cast(IntegerType())\n)\n\ndf = df.withColumn(\n    \"CommercialData_EstimatedHHIncomeAmount\", \n    expr(\n        \"substring(CommercialData_EstimatedHHIncomeAmount, 2, length(CommercialData_EstimatedHHIncomeAmount))\"\n    ).cast(IntegerType())\n)\ndf = df.withColumn(\n    \"CommercialData_EstHomeValue\", \n    expr(\n        \"substring(CommercialData_EstHomeValue, 2, length(CommercialData_EstHomeValue))\"\n    ).cast(IntegerType())\n)\ndf = df.withColumn(\"Voters_Age\", df[\"Voters_Age\"].cast(IntegerType()))"}, {"cell_type": "code", "execution_count": 25, "id": "94b076b1-573b-44fe-a8c1-947fb66c00d0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+----------+-------------+------------------------+-----------------------------+--------------------------------------+---------------------------+---------------------------------------------------+---------------------------------------------------+---------------------------------------------------+\n|County|Voters_Age|Voters_Gender|CommercialData_Education|EthnicGroups_EthnicGroup1Desc|CommercialData_EstimatedHHIncomeAmount|CommercialData_EstHomeValue|ElectionReturns_G18CountyTurnoutAllRegisteredVoters|ElectionReturns_G14CountyTurnoutAllRegisteredVoters|ElectionReturns_G08CountyTurnoutAllRegisteredVoters|\n+------+----------+-------------+------------------------+-----------------------------+--------------------------------------+---------------------------+---------------------------------------------------+---------------------------------------------------+---------------------------------------------------+\n|NAVAJO|        63|            F|     HS Diploma - Likely|                     European|                                  9000|                      12500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        58|            M|    HS Diploma - Extr...|                        Other|                                  9000|                       7500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        80|            F|     HS Diploma - Likely|                        Other|                                  9000|                       7500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        65|            F|     HS Diploma - Likely|                        Other|                                  1000|                       7500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        63|            F|     HS Diploma - Likely|                     European|                                  1000|                       7500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        40|            M|    Some College - Li...|         Hispanic and Port...|                                  4000|                       7500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        60|            F|    Grad Degree - Ext...|                        Other|                                  1000|                      62500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        47|            M|    Some College - Li...|                        Other|                                  2000|                       7500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        54|            F|    Bach Degree - Ext...|                     European|                                  4000|                       7500|                                                 53|                                                 42|                                                 55|\n|NAVAJO|        61|            M|    Bach Degree - Ext...|                     European|                                  1000|                      87500|                                                 53|                                                 42|                                                 55|\n+------+----------+-------------+------------------------+-----------------------------+--------------------------------------+---------------------------+---------------------------------------------------+---------------------------------------------------+---------------------------------------------------+\nonly showing top 10 rows\n\n"}], "source": "# select some variables we are interested in from the data\nspark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000) \ndf_need = df.select(\n    \"County\", \"Voters_Age\", \"Voters_Gender\",\n    \"CommercialData_Education\", \"EthnicGroups_EthnicGroup1Desc\",\n    \"CommercialData_EstimatedHHIncomeAmount\", \n    \"CommercialData_EstHomeValue\",\n    \"ElectionReturns_G18CountyTurnoutAllRegisteredVoters\",\n    \"ElectionReturns_G14CountyTurnoutAllRegisteredVoters\",\n    \"ElectionReturns_G08CountyTurnoutAllRegisteredVoters\"\n)\n# Drop missing values \ndf_need = df_need.na.drop()\n\ndf_need.show(10)"}, {"cell_type": "code", "execution_count": 6, "id": "79801160-a518-4860-bbbd-7827438ef4e8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+--------+--------+--------+--------+--------+------+\n|    County|age18-25|age26-35|age36-45|age46-55|age56-65|age66+|\n+----------+--------+--------+--------+--------+--------+------+\n|      YUMA|    2452|    5981|    6821|    7060|    8335| 14603|\n|  COCONINO|    1984|    4043|    5041|    5558|    6877| 10859|\n|   COCHISE|    1354|    3475|    4694|    5225|    8112| 17116|\n|  GREENLEE|      89|     241|     296|     352|     388|   600|\n|    MOHAVE|    1582|    4365|    5481|    7154|   13474| 33306|\n|SANTA CRUZ|     820|    1698|    1701|    2063|    2520|  4424|\n|   YAVAPAI|    2028|    4969|    6521|    8693|   16249| 44347|\n|      GILA|     377|     925|    1285|    1753|    3374|  8918|\n|    LA PAZ|     119|     245|     300|     364|     599|  1452|\n|    APACHE|     143|     478|     858|    1091|    1820|  3095|\n|      PIMA|   14266|   35469|   40343|   45635|   62966|126401|\n|    GRAHAM|     454|    1119|    1448|    1498|    1662|  3055|\n|     PINAL|    4837|   13182|   17168|   17791|   20858| 42920|\n|    NAVAJO|     667|    1584|    2474|    2976|    4390|  8845|\n|  MARICOPA|   64062|  154601|  179019|  210121|  242555|381693|\n+----------+--------+--------+--------+--------+--------+------+\n\n"}], "source": "from pyspark.ml.feature import Bucketizer\nfrom pyspark.sql.functions import count\n\n\n# Define the age groups or bins\nsplits = [17, 25, 35, 45, 55, 65, float(\"inf\")]\n\n# Create the Bucketizer object and set the input and output columns\nbucketizer = Bucketizer(splits=splits, inputCol=\"Voters_Age\", outputCol=\"AgeGroup\")\n\n# Apply the Bucketizer transformation to the dataframe\nage_bucketed_df = bucketizer.transform(df_need)\n\n# Group by county and age group and count the number of records in each group\ncounties_age_count_df = age_bucketed_df.groupBy(\"County\", \"AgeGroup\").agg(count(\"*\").alias(\"Count\"))\n\n# Pivot the data to have age groups as columns\nage_pivot_df = counties_age_count_df.groupBy(\"County\").pivot(\"AgeGroup\").sum(\"Count\")\n\n# Rename the columns to reflect the age groups\nage_groups = [\n    \"age18-25\", \"age26-35\", \"age36-45\", \"age46-55\", \"age56-65\", \"age66+\"\n]\nfor i in range(len(age_groups)):\n    age_pivot_df = age_pivot_df.withColumnRenamed(\n        str(float(i)), age_groups[i]\n    )\n\nage_pivot_df.show()"}, {"cell_type": "code", "execution_count": 7, "id": "9eea4f15-6670-424a-9bf6-0bb8543af4e5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 33:=================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+--------+-----------+------------+------------+--------+\n|    County|inc0-50k|inc50k-100k|inc100k-150k|inc150k-200k|inc200k+|\n+----------+--------+-----------+------------+------------+--------+\n|      YUMA|   14834|      21199|        5981|        1681|    1557|\n|  COCONINO|    7044|      14341|        7324|        2688|    2965|\n|   COCHISE|   12552|      17862|        6545|        1608|    1409|\n|  GREENLEE|     465|       1110|         279|          45|      67|\n|    MOHAVE|   24260|      29423|        7197|        2238|    2244|\n|SANTA CRUZ|    5730|       5236|        1356|         461|     443|\n|   YAVAPAI|   22085|      38550|       12441|        4567|    5164|\n|      GILA|    6610|       6863|        1850|         646|     663|\n|    LA PAZ|    1488|       1199|         249|          61|      82|\n|    APACHE|    3376|       3058|         720|         173|     158|\n|      PIMA|   88456|     135292|       59159|       20441|   21732|\n|    GRAHAM|    2750|       4614|        1379|         348|     145|\n|     PINAL|   30817|      56412|       19507|        5715|    4305|\n|    NAVAJO|    7033|       9623|        2782|        1008|     490|\n|  MARICOPA|  234218|     460052|      293672|      116821|  127288|\n+----------+--------+-----------+------------+------------+--------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# bucketize household income\nsplits = [-float(\"inf\"), 50000, 100000, 150000, 200000, float(\"inf\")]\nbucketizer = Bucketizer(\n    splits=splits, inputCol=\"CommercialData_EstimatedHHIncomeAmount\", \n    outputCol=\"HHIncomeGroup\"\n)\nincome_bucketed_df = bucketizer.transform(df_need)\ncounties_income_count_df = income_bucketed_df.groupBy(\"County\", \"HHIncomeGroup\") \\\n    .agg(count(\"*\").alias(\"Count\"))\nincome_pivot_df = counties_income_count_df.groupBy(\"County\").pivot(\"HHIncomeGroup\").sum(\"Count\")\n\n# rename columns\nincome_groups = [\n    \"inc0-50k\", \"inc50k-100k\", \"inc100k-150k\", \"inc150k-200k\", \"inc200k+\"\n]\nfor i in range(len(income_groups)):\n    income_pivot_df = income_pivot_df.withColumnRenamed(\n        str(float(i)), income_groups[i]\n    )\n\nincome_pivot_df.show()"}, {"cell_type": "code", "execution_count": 8, "id": "d2ba6753-27f5-4088-ae4f-c3b3ef57907f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 52:=================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+-----------+--------------+---------------+---------------+---------------+-----------+\n|    County|hvalue0-50k|hvalue50k-100k|hvalue100k-150k|hvalue150k-200k|hvalue200k-250k|hvalue250k+|\n+----------+-----------+--------------+---------------+---------------+---------------+-----------+\n|      YUMA|        688|          3120|          11375|          11108|           7609|      11352|\n|  COCONINO|        319|          1599|           2109|           1685|           2246|      26404|\n|   COCHISE|        814|          4673|           8675|          10170|           5863|       9781|\n|  GREENLEE|        158|          1050|            553|             92|             47|         66|\n|    MOHAVE|       1157|          5972|           7751|          11271|           8411|      30800|\n|SANTA CRUZ|        142|           540|           2819|           4868|           2075|       2782|\n|   YAVAPAI|        483|          1471|           4072|           7153|           7491|      62137|\n|      GILA|        312|          1490|           1864|           2896|           2545|       7525|\n|    LA PAZ|        134|           598|            762|            607|            452|        526|\n|    APACHE|        810|          1514|           2972|           1315|            271|        603|\n|      PIMA|       3611|         14885|          25795|          46802|          67778|     166209|\n|    GRAHAM|        382|          1130|           1584|           3469|           1701|        970|\n|     PINAL|        706|          6617|           9549|          12462|          18910|      68512|\n|    NAVAJO|        995|          3208|           4713|           5645|           2427|       3948|\n|  MARICOPA|       6610|         21202|          40164|          63741|         113379|     986955|\n+----------+-----------+--------------+---------------+---------------+---------------+-----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# bucketize home value\nsplits = [-float(\"inf\"), 50000, 100000, 150000, 200000, 250000, float(\"inf\")]\nbucketizer = Bucketizer(\n    splits=splits, inputCol=\"CommercialData_EstHomeValue\", \n    outputCol=\"HomeValueGroup\"\n)\nhomevalue_bucketed_df = bucketizer.transform(df_need)\ncounties_homevalue_count_df = homevalue_bucketed_df.groupBy(\"County\", \"HomeValueGroup\") \\\n    .agg(count(\"*\").alias(\"Count\"))\nhomevalue_pivot_df = counties_homevalue_count_df.groupBy(\"County\").pivot(\"HomeValueGroup\").sum(\"Count\")\n\n# rename columns\nhomevalue_groups = [\n    \"hvalue0-50k\", \"hvalue50k-100k\", \"hvalue100k-150k\", \"hvalue150k-200k\", \n    \"hvalue200k-250k\", \"hvalue250k+\"\n]\nfor i in range(len(homevalue_groups)):\n    homevalue_pivot_df = homevalue_pivot_df.withColumnRenamed(\n        str(float(i)), homevalue_groups[i]\n    )\n\nhomevalue_pivot_df.show()"}, {"cell_type": "code", "execution_count": 9, "id": "d6f8006f-127f-41f1-ae36-e06367d2e629", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 71:=================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------+------------------------------+--------------------+------------------------------+--------------------+-----------------------------+-------------------+------------------------------+-----------------------------+---------------------+------------------------------+----------------------------------------------+\n|  County|Bach Degree - Extremely Likely|Bach Degree - Likely|Grad Degree - Extremely Likely|Grad Degree - Likely|HS Diploma - Extremely Likely|HS Diploma - Likely|Less than HS Diploma - Ex Like|Less than HS Diploma - Likely|Some College - Likely|Some College -Extremely Likely|Vocational Technical Degree - Extremely Likely|\n+--------+------------------------------+--------------------+------------------------------+--------------------+-----------------------------+-------------------+------------------------------+-----------------------------+---------------------+------------------------------+----------------------------------------------+\n|    YUMA|                          6916|                2898|                          2149|                1688|                         5943|               6129|                            11|                         6488|                10605|                          2355|                                            70|\n|COCONINO|                          5583|                4192|                          3349|                3581|                         3598|               3517|                             5|                         1392|                 7385|                          1716|                                            44|\n| COCHISE|                          6572|                2797|                          2884|                2187|                         5696|               4355|                            14|                         2620|                 9926|                          2860|                                            65|\n|GREENLEE|                           216|                 119|                            69|                  40|                          402|                360|                          null|                          118|                  531|                           104|                                             7|\n|  MOHAVE|                          9163|                2424|                          3146|                1963|                        11948|              11117|                            42|                         5001|                15047|                          5357|                                           154|\n+--------+------------------------------+--------------------+------------------------------+--------------------+-----------------------------+-------------------+------------------------------+-----------------------------+---------------------+------------------------------+----------------------------------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# pivot education\nedu_count_df = df_need.select(\"County\", \"CommercialData_Education\") \\\n    .groupBy(\"County\", \"CommercialData_Education\").agg(count(\"*\").alias(\"Count\"))\nedu_pivot_df = edu_count_df.groupBy(\"County\").pivot(\"CommercialData_Education\").sum(\"Count\")\n\nedu_pivot_df.show(5)"}, {"cell_type": "code", "execution_count": 10, "id": "807f6140-c27a-4120-81a5-822196d14e69", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 77:=================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+------+------+----------+------+-------+-------+\n|    County|  Bach|  Grad|HighSchool|LessHS|College|VocTech|\n+----------+------+------+----------+------+-------+-------+\n|      YUMA|  9814|  3837|     12072|  6499|  12960|     70|\n|  COCONINO|  9775|  6930|      7115|  1397|   9101|     44|\n|   COCHISE|  9369|  5071|     10051|  2634|  12786|     65|\n|  GREENLEE|   335|   109|       762|  null|    635|      7|\n|    MOHAVE| 11587|  5109|     23065|  5043|  20404|    154|\n|SANTA CRUZ|  3269|  1274|      4070|  null|   2861|     18|\n|   YAVAPAI| 19338| 12185|     21784|  3941|  25450|    109|\n|      GILA|  3442|  1856|      5335|  1183|   4786|     30|\n|    LA PAZ|   498|   231|      1201|  null|    795|      9|\n|    APACHE|  1546|   496|      2967|  null|   1821|     49|\n|      PIMA| 85320| 58965|     74454| 16921|  88919|    501|\n|    GRAHAM|  1969|   880|      2699|   621|   3053|     14|\n|     PINAL| 25005| 11422|     33948|  7857|  38348|    176|\n|    NAVAJO|  4476|  2261|      6346|  1229|   6568|     56|\n|  MARICOPA|353831|191654|    281151| 63122| 340735|   1558|\n+----------+------+------+----------+------+-------+-------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# combine columns in edu_pivot_df\nedu_pivot_df = edu_pivot_df.withColumn(\n    \"Bach\", \n    edu_pivot_df['Bach Degree - Extremely Likely'] + edu_pivot_df['Bach Degree - Likely']\n)\nedu_pivot_df = edu_pivot_df.withColumn(\n    \"Grad\", \n    edu_pivot_df['Grad Degree - Extremely Likely'] + edu_pivot_df['Grad Degree - Likely']\n)\nedu_pivot_df = edu_pivot_df.withColumn(\n    \"HighSchool\", \n    edu_pivot_df['HS Diploma - Extremely Likely'] + edu_pivot_df['HS Diploma - Likely']\n)\nedu_pivot_df = edu_pivot_df.withColumn(\n    \"LessHS\", \n    edu_pivot_df['Less than HS Diploma - Ex Like'] + edu_pivot_df['Less than HS Diploma - Likely']\n)\nedu_pivot_df = edu_pivot_df.withColumn(\n    \"College\", \n    edu_pivot_df['Some College - Likely'] + edu_pivot_df['Some College -Extremely Likely']\n)\nedu_pivot_df = edu_pivot_df.withColumn(\n    \"VocTech\", \n    edu_pivot_df['Vocational Technical Degree - Extremely Likely']\n)\n\nedu_pivot_df = edu_pivot_df.select(\n    \"County\",\n    \"Bach\", \"Grad\", \"HighSchool\", \"LessHS\", \n    \"College\", \"VocTech\"\n)\nedu_pivot_df.show()"}, {"cell_type": "code", "execution_count": 11, "id": "41b09777-6284-4435-93ec-c56ad5e74afb", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 96:=================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+--------------------+--------+-----------------------+-----------------------+-----+\n|    County|East and South Asian|European|Hispanic and Portuguese|Likely African-American|Other|\n+----------+--------------------+--------+-----------------------+-----------------------+-----+\n|  COCONINO|                 567|   28490|                   3647|                    114| 1544|\n|   COCHISE|                 592|   29403|                   9215|                    371|  395|\n|  GREENLEE|                   7|    1196|                    737|                      3|   23|\n|    MOHAVE|                 596|   57230|                   6563|                     81|  892|\n|SANTA CRUZ|                  90|    3372|                   9648|                      3|  113|\n|   YAVAPAI|                 844|   74273|                   6388|                     73| 1229|\n|      GILA|                 129|   13978|                   2227|                     14|  284|\n|      YUMA|                 519|   21968|                  22190|                    112|  463|\n|    LA PAZ|                  22|    2338|                    657|                      2|   60|\n|    APACHE|                  90|    5322|                    556|                     27| 1490|\n|      PIMA|                7024|  227012|                  81834|                   2394| 6816|\n|    GRAHAM|                  60|    6737|                   2330|                     16|   93|\n|     PINAL|                1304|   89052|                  23041|                   1634| 1725|\n|    NAVAJO|                 196|   17265|                   2005|                     97| 1373|\n|  MARICOPA|               38357|  917530|                 222199|                  18512|35453|\n+----------+--------------------+--------+-----------------------+-----------------------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# pivot ethnic \neth_count_df = df_need.select(\"County\", \"EthnicGroups_EthnicGroup1Desc\") \\\n    .groupBy(\"County\", \"EthnicGroups_EthnicGroup1Desc\").agg(count(\"*\").alias(\"Count\"))\neth_pivot_df = eth_count_df.groupBy(\"County\").pivot(\"EthnicGroups_EthnicGroup1Desc\").sum(\"Count\")\n\neth_pivot_df.show()"}, {"cell_type": "code", "execution_count": 12, "id": "2205c123-a888-4542-98fe-436ce971ade7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 115:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+------+------+\n|    County|     F|     M|\n+----------+------+------+\n|      YUMA| 23339| 21913|\n|  COCONINO| 17841| 16521|\n|  GREENLEE|   985|   981|\n|    MOHAVE| 33505| 31857|\n|SANTA CRUZ|  6774|  6452|\n|   COCHISE| 20710| 19266|\n|   YAVAPAI| 43911| 38896|\n|    LA PAZ|  1644|  1435|\n|    APACHE|  4419|  3066|\n|      PIMA|172745|152335|\n|    GRAHAM|  4788|  4448|\n|    NAVAJO| 11284|  9652|\n|      GILA|  8654|  7978|\n|     PINAL| 60548| 56208|\n|  MARICOPA|647374|584677|\n+----------+------+------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# pivot gender\ngender_count_df = df_need.select(\"County\", \"Voters_Gender\") \\\n    .groupBy(\"County\", \"Voters_Gender\").agg(count(\"*\").alias(\"Count\"))\ngender_pivot_df = gender_count_df.groupBy(\"County\").pivot(\"Voters_Gender\").sum(\"Count\")\n\ngender_pivot_df.show()"}, {"cell_type": "code", "execution_count": 13, "id": "82233744-e023-4c9a-a288-f397d567952f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 124:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+----------+\n|    County|G18Turnout|\n+----------+----------+\n|  COCONINO|      61.0|\n|   COCHISE|      60.0|\n|  GREENLEE|      56.0|\n|    MOHAVE|      53.0|\n|SANTA CRUZ|      47.0|\n|   YAVAPAI|      73.0|\n|      GILA|      66.0|\n|      YUMA|      43.0|\n|    LA PAZ|      47.0|\n|      PIMA|      67.0|\n|    GRAHAM|      57.0|\n|    NAVAJO|      53.0|\n|     PINAL|      59.0|\n|    APACHE|      48.0|\n|  MARICOPA|      62.0|\n+----------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# turnout by county\nturnout_df = df_need.select(\"County\", \"ElectionReturns_G18CountyTurnoutAllRegisteredVoters\")\nturnout_df = turnout_df.groupBy(\"County\").agg(\n    mean(\"ElectionReturns_G18CountyTurnoutAllRegisteredVoters\").alias(\n        \"G18Turnout\"\n    )\n)\nturnout_df.show()"}, {"cell_type": "code", "execution_count": 14, "id": "6a4e0b0c-ee7f-436a-850b-54b87dd4171c", "metadata": {}, "outputs": [], "source": "import copy\n\n\ndef count2ratio(pivot_df):\n    \"\"\"\n    convert count to ratio\n    \"\"\"\n    pivot_pddf = pivot_df.toPandas()\n    pivot_arr = pivot_pddf.iloc[:, 1:].to_numpy()\n    \n    new_pivot_arr = copy.deepcopy(pivot_arr).astype('float')\n    \n    # calculate values in np.arr\n    for rowi in range(pivot_arr.shape[0]):\n        for colj in range(pivot_arr.shape[1]):\n            new_pivot_arr[rowi, colj] = pivot_arr[rowi, colj] / np.nansum(pivot_arr[rowi, :])\n\n    # update values in pd.df\n    for rowi in range(pivot_pddf.shape[0]):\n        pivot_pddf.iloc[rowi, 1:] = new_pivot_arr[rowi, :]\n\n    new_pivot_df = spark.createDataFrame(pivot_pddf)\n    \n    return new_pivot_df"}, {"cell_type": "code", "execution_count": 15, "id": "ef5023b4-85ff-4ac0-8123-4b719fade54f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# convert count to ratio: age\nage_ratio_pivot_df = count2ratio(age_pivot_df)\ngender_ratio_pivot_df = count2ratio(gender_pivot_df)\nedu_ratio_pivot_df = count2ratio(edu_pivot_df)\nincome_ratio_pivot_df = count2ratio(income_pivot_df)\nhomevalue_ratio_pivot_df = count2ratio(homevalue_pivot_df)\neth_ratio_pivot_df = count2ratio(eth_pivot_df)"}, {"cell_type": "code", "execution_count": 16, "id": "e392794d-da68-4166-aab8-eb7b8268b8d5", "metadata": {}, "outputs": [], "source": "# rename county columns\nage_ratio_pivot_df = age_ratio_pivot_df.withColumn(\n    \"ageCounty\", age_ratio_pivot_df[\"County\"]\n)\nage_ratio_pivot_df = age_ratio_pivot_df.drop(\"County\")\n###\nedu_ratio_pivot_df = edu_ratio_pivot_df.withColumn(\n    \"eduCounty\", edu_ratio_pivot_df[\"County\"]\n)\nedu_ratio_pivot_df = edu_ratio_pivot_df.drop(\"County\")\n###\nincome_ratio_pivot_df = income_ratio_pivot_df.withColumn(\n    \"incCounty\", income_ratio_pivot_df[\"County\"]\n)\nincome_ratio_pivot_df = income_ratio_pivot_df.drop(\"County\")\n###\nhomevalue_ratio_pivot_df = homevalue_ratio_pivot_df.withColumn(\n    \"hvalCounty\", homevalue_ratio_pivot_df[\"County\"]\n)\nhomevalue_ratio_pivot_df = homevalue_ratio_pivot_df.drop(\"County\")\n###\neth_ratio_pivot_df = eth_ratio_pivot_df.withColumn(\n    \"ethCounty\", eth_ratio_pivot_df[\"County\"]\n)\neth_ratio_pivot_df = eth_ratio_pivot_df.drop(\"County\")\n###\nturnout_df = turnout_df.withColumn(\n    \"toutCounty\", turnout_df[\"County\"]\n)\nturnout_df = turnout_df.drop(\"County\")"}, {"cell_type": "markdown", "id": "890cb241-0fd1-4c2c-b0c5-43368e5c58ef", "metadata": {}, "source": "# All factors"}, {"cell_type": "code", "execution_count": 40, "id": "8e9602ef-21ec-492f-b53f-21a2d8c57818", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- Bach: double (nullable = true)\n |-- Grad: double (nullable = true)\n |-- HighSchool: double (nullable = true)\n |-- LessHS: double (nullable = true)\n |-- College: double (nullable = true)\n |-- VocTech: double (nullable = true)\n |-- inc0-50k: double (nullable = true)\n |-- inc50k-100k: double (nullable = true)\n |-- inc100k-150k: double (nullable = true)\n |-- inc150k-200k: double (nullable = true)\n |-- inc200k+: double (nullable = true)\n |-- hvalue0-50k: double (nullable = true)\n |-- hvalue50k-100k: double (nullable = true)\n |-- hvalue100k-150k: double (nullable = true)\n |-- hvalue150k-200k: double (nullable = true)\n |-- hvalue200k-250k: double (nullable = true)\n |-- hvalue250k+: double (nullable = true)\n |-- East and South Asian: double (nullable = true)\n |-- European: double (nullable = true)\n |-- Hispanic and Portuguese: double (nullable = true)\n |-- Likely African-American: double (nullable = true)\n |-- Other: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    edu_ratio_pivot_df, joined_pivot_df.County==edu_ratio_pivot_df.eduCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    income_ratio_pivot_df, joined_pivot_df.County==income_ratio_pivot_df.incCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    homevalue_ratio_pivot_df, joined_pivot_df.County==homevalue_ratio_pivot_df.hvalCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    eth_ratio_pivot_df, joined_pivot_df.County==eth_ratio_pivot_df.ethCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"eduCounty\", \"incCounty\", \"hvalCounty\", \"ethCounty\",\"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 41, "id": "419e30a6-4d19-43ee-a009-b699f0a9fd5d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 02:33:40 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 430:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 3.0138568866708533\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "bd9414e6-860e-4767-a69e-56ac1a5b6c7f", "metadata": {}, "source": "# Gender + Age"}, {"cell_type": "code", "execution_count": 45, "id": "be856c87-c254-4c10-b65c-1462d3470538", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 46, "id": "c1ad5ea4-2b9d-4f21-ab6b-5cb6c81f7f97", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 02:37:08 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 547:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 8.794529549668932\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "776afc00-8f38-4efa-892f-45de4d47dabf", "metadata": {}, "source": "# Gender + Age + Education"}, {"cell_type": "code", "execution_count": 19, "id": "c29c21bb-a2e4-4877-9662-3d09c5df29fc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- Bach: double (nullable = true)\n |-- Grad: double (nullable = true)\n |-- HighSchool: double (nullable = true)\n |-- LessHS: double (nullable = true)\n |-- College: double (nullable = true)\n |-- VocTech: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    edu_ratio_pivot_df, joined_pivot_df.County==edu_ratio_pivot_df.eduCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"eduCounty\", \"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 20, "id": "334057f5-1be0-4bec-9a58-6853a5a07515", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 02:12:15 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 174:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 6.18238424881534\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "6a176114-0c6b-4932-9b7f-75af39cafeb4", "metadata": {}, "source": "# Gender + Age + Income"}, {"cell_type": "code", "execution_count": 24, "id": "93a52fc1-f4c0-4b1c-833d-6af29f82d0fd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- inc0-50k: double (nullable = true)\n |-- inc50k-100k: double (nullable = true)\n |-- inc100k-150k: double (nullable = true)\n |-- inc150k-200k: double (nullable = true)\n |-- inc200k+: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    income_ratio_pivot_df, joined_pivot_df.County==income_ratio_pivot_df.incCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"incCounty\", \"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 25, "id": "5bee5bb5-9bac-4713-b05c-0e0151d9bcb8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 02:15:16 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 216:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 3.337507802737445\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "0f91cccc-bdeb-4a02-a277-23ec61097584", "metadata": {}, "source": "# Gender + Age + Housevalue"}, {"cell_type": "code", "execution_count": 26, "id": "f90c26e1-58d7-4ca2-bcae-842914e84aa6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- hvalue0-50k: double (nullable = true)\n |-- hvalue50k-100k: double (nullable = true)\n |-- hvalue100k-150k: double (nullable = true)\n |-- hvalue150k-200k: double (nullable = true)\n |-- hvalue200k-250k: double (nullable = true)\n |-- hvalue250k+: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    homevalue_ratio_pivot_df, joined_pivot_df.County==homevalue_ratio_pivot_df.hvalCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"hvalCounty\", \"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 27, "id": "8300f064-55a5-41fd-9044-eeb806a09abc", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 02:16:52 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 258:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 5.851317515454675\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "e79d78a4-5142-4f28-8888-df9191c62699", "metadata": {}, "source": "# Gender + Age + Ethnic"}, {"cell_type": "code", "execution_count": 52, "id": "1f6a15a6-8abf-48bd-b1c8-c2d86d9a40d0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- East and South Asian: double (nullable = true)\n |-- European: double (nullable = true)\n |-- Hispanic and Portuguese: double (nullable = true)\n |-- Likely African-American: double (nullable = true)\n |-- Other: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    eth_ratio_pivot_df, joined_pivot_df.County==eth_ratio_pivot_df.ethCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"ethCounty\", \"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 53, "id": "c67bc149-85dd-4c99-a6d1-111d56651867", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 02:45:29 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 689:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 8.283278839525645\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "141c2df3-cd26-4b0f-a283-c692768598f5", "metadata": {}, "source": "# Gender + Age + Income + Housevalue"}, {"cell_type": "code", "execution_count": 19, "id": "3d0a1d33-2b1f-4d8e-a26a-d2db9338dd08", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- inc0-50k: double (nullable = true)\n |-- inc50k-100k: double (nullable = true)\n |-- inc100k-150k: double (nullable = true)\n |-- inc150k-200k: double (nullable = true)\n |-- inc200k+: double (nullable = true)\n |-- hvalue0-50k: double (nullable = true)\n |-- hvalue50k-100k: double (nullable = true)\n |-- hvalue100k-150k: double (nullable = true)\n |-- hvalue150k-200k: double (nullable = true)\n |-- hvalue200k-250k: double (nullable = true)\n |-- hvalue250k+: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    income_ratio_pivot_df, joined_pivot_df.County==income_ratio_pivot_df.incCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    homevalue_ratio_pivot_df, joined_pivot_df.County==homevalue_ratio_pivot_df.hvalCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"eduCounty\", \"incCounty\", \"hvalCounty\", \"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 20, "id": "a32af7f9-370a-481b-952b-ad216d5fe696", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 03:54:23 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 257:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 3.241527417746146\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "f9c0315e-d99d-41a4-92d8-9652bdd0a042", "metadata": {}, "source": "# Gender + Age + Education + Income + Housevalue"}, {"cell_type": "code", "execution_count": 17, "id": "c91bfb01-3365-446a-88e3-b3a51db7b481", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- Bach: double (nullable = true)\n |-- Grad: double (nullable = true)\n |-- HighSchool: double (nullable = true)\n |-- LessHS: double (nullable = true)\n |-- College: double (nullable = true)\n |-- VocTech: double (nullable = true)\n |-- inc0-50k: double (nullable = true)\n |-- inc50k-100k: double (nullable = true)\n |-- inc100k-150k: double (nullable = true)\n |-- inc150k-200k: double (nullable = true)\n |-- inc200k+: double (nullable = true)\n |-- hvalue0-50k: double (nullable = true)\n |-- hvalue50k-100k: double (nullable = true)\n |-- hvalue100k-150k: double (nullable = true)\n |-- hvalue150k-200k: double (nullable = true)\n |-- hvalue200k-250k: double (nullable = true)\n |-- hvalue250k+: double (nullable = true)\n |-- G18Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    edu_ratio_pivot_df, joined_pivot_df.County==edu_ratio_pivot_df.eduCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    income_ratio_pivot_df, joined_pivot_df.County==income_ratio_pivot_df.incCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    homevalue_ratio_pivot_df, joined_pivot_df.County==homevalue_ratio_pivot_df.hvalCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"eduCounty\", \"incCounty\", \"hvalCounty\", \"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 18, "id": "e5f888b7-4827-44fd-ade2-4c1289165fc5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 03:35:29 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 207:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 4.153913817112722\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G18Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G18Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "ff51484c-31c1-44d9-94c9-ec724f9985ce", "metadata": {}, "source": "# All + turnout 2014"}, {"cell_type": "code", "execution_count": 27, "id": "044c8772-2d83-46f9-b245-e7e0b3c5edf9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 270:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+----------+\n|    County|G14Turnout|\n+----------+----------+\n|  COCONINO|      44.0|\n|   COCHISE|      47.0|\n|  GREENLEE|      41.0|\n|    MOHAVE|      35.0|\n|SANTA CRUZ|      37.0|\n|   YAVAPAI|      50.0|\n|      GILA|      48.0|\n|      YUMA|      29.0|\n|    LA PAZ|      32.0|\n|      PIMA|      47.0|\n|    GRAHAM|      36.0|\n|    NAVAJO|      42.0|\n|     PINAL|      37.0|\n|    APACHE|      41.0|\n|  MARICOPA|      39.0|\n+----------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# turnout by county\nturnout_df = df_need.select(\"County\", \"ElectionReturns_G14CountyTurnoutAllRegisteredVoters\")\nturnout_df = turnout_df.groupBy(\"County\").agg(\n    mean(\"ElectionReturns_G14CountyTurnoutAllRegisteredVoters\").alias(\n        \"G14Turnout\"\n    )\n)\nturnout_df.show()"}, {"cell_type": "code", "execution_count": 28, "id": "87fe8e55-5e19-47b0-b7a0-036b0067d14e", "metadata": {}, "outputs": [], "source": "turnout_df = turnout_df.withColumn(\n    \"toutCounty\", turnout_df[\"County\"]\n)\nturnout_df = turnout_df.drop(\"County\")"}, {"cell_type": "code", "execution_count": 29, "id": "c06ac56f-17a2-4c75-b2ba-afc08f4be332", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- Bach: double (nullable = true)\n |-- Grad: double (nullable = true)\n |-- HighSchool: double (nullable = true)\n |-- LessHS: double (nullable = true)\n |-- College: double (nullable = true)\n |-- VocTech: double (nullable = true)\n |-- inc0-50k: double (nullable = true)\n |-- inc50k-100k: double (nullable = true)\n |-- inc100k-150k: double (nullable = true)\n |-- inc150k-200k: double (nullable = true)\n |-- inc200k+: double (nullable = true)\n |-- hvalue0-50k: double (nullable = true)\n |-- hvalue50k-100k: double (nullable = true)\n |-- hvalue100k-150k: double (nullable = true)\n |-- hvalue150k-200k: double (nullable = true)\n |-- hvalue200k-250k: double (nullable = true)\n |-- hvalue250k+: double (nullable = true)\n |-- East and South Asian: double (nullable = true)\n |-- European: double (nullable = true)\n |-- Hispanic and Portuguese: double (nullable = true)\n |-- Likely African-American: double (nullable = true)\n |-- Other: double (nullable = true)\n |-- G14Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    edu_ratio_pivot_df, joined_pivot_df.County==edu_ratio_pivot_df.eduCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    income_ratio_pivot_df, joined_pivot_df.County==income_ratio_pivot_df.incCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    homevalue_ratio_pivot_df, joined_pivot_df.County==homevalue_ratio_pivot_df.hvalCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    eth_ratio_pivot_df, joined_pivot_df.County==eth_ratio_pivot_df.ethCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"eduCounty\", \"incCounty\", \"hvalCounty\", \"ethCounty\",\"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 32, "id": "74f16290-a8b6-4ae0-a750-a86dfd76eaff", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 04:02:34 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 361:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 4.43245605355165\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G14Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G14Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "markdown", "id": "1001684c-dec2-43ee-b17b-70c75b2c810b", "metadata": {}, "source": "# All + turnout 2008"}, {"cell_type": "code", "execution_count": 33, "id": "c7de39ed-e983-448c-bfcd-90dee5b26b9e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 375:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+----------+\n|    County|G08Turnout|\n+----------+----------+\n|  COCONINO|      62.0|\n|   COCHISE|      64.0|\n|  GREENLEE|      63.0|\n|    MOHAVE|      56.0|\n|SANTA CRUZ|      55.0|\n|   YAVAPAI|      76.0|\n|      GILA|      62.0|\n|      YUMA|      55.0|\n|    LA PAZ|      58.0|\n|      PIMA|      72.0|\n|    GRAHAM|      62.0|\n|    NAVAJO|      55.0|\n|     PINAL|      65.0|\n|    APACHE|      53.0|\n|  MARICOPA|      69.0|\n+----------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# turnout by county\nturnout_df = df_need.select(\"County\", \"ElectionReturns_G08CountyTurnoutAllRegisteredVoters\")\nturnout_df = turnout_df.groupBy(\"County\").agg(\n    mean(\"ElectionReturns_G08CountyTurnoutAllRegisteredVoters\").alias(\n        \"G08Turnout\"\n    )\n)\nturnout_df.show()"}, {"cell_type": "code", "execution_count": 34, "id": "4fcdec06-76e0-4fdb-bb54-07c7264c4a8a", "metadata": {}, "outputs": [], "source": "turnout_df = turnout_df.withColumn(\n    \"toutCounty\", turnout_df[\"County\"]\n)\nturnout_df = turnout_df.drop(\"County\")"}, {"cell_type": "code", "execution_count": 35, "id": "9759fb06-18d0-46e4-8a96-c1fea5f7f716", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- County: string (nullable = true)\n |-- F: double (nullable = true)\n |-- M: double (nullable = true)\n |-- age18-25: double (nullable = true)\n |-- age26-35: double (nullable = true)\n |-- age36-45: double (nullable = true)\n |-- age46-55: double (nullable = true)\n |-- age56-65: double (nullable = true)\n |-- age66+: double (nullable = true)\n |-- Bach: double (nullable = true)\n |-- Grad: double (nullable = true)\n |-- HighSchool: double (nullable = true)\n |-- LessHS: double (nullable = true)\n |-- College: double (nullable = true)\n |-- VocTech: double (nullable = true)\n |-- inc0-50k: double (nullable = true)\n |-- inc50k-100k: double (nullable = true)\n |-- inc100k-150k: double (nullable = true)\n |-- inc150k-200k: double (nullable = true)\n |-- inc200k+: double (nullable = true)\n |-- hvalue0-50k: double (nullable = true)\n |-- hvalue50k-100k: double (nullable = true)\n |-- hvalue100k-150k: double (nullable = true)\n |-- hvalue150k-200k: double (nullable = true)\n |-- hvalue200k-250k: double (nullable = true)\n |-- hvalue250k+: double (nullable = true)\n |-- East and South Asian: double (nullable = true)\n |-- European: double (nullable = true)\n |-- Hispanic and Portuguese: double (nullable = true)\n |-- Likely African-American: double (nullable = true)\n |-- Other: double (nullable = true)\n |-- G08Turnout: double (nullable = true)\n\n"}], "source": "# join pivot tables\njoined_pivot_df = gender_ratio_pivot_df.join(\n    age_ratio_pivot_df, gender_ratio_pivot_df.County==age_ratio_pivot_df.ageCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    edu_ratio_pivot_df, joined_pivot_df.County==edu_ratio_pivot_df.eduCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    income_ratio_pivot_df, joined_pivot_df.County==income_ratio_pivot_df.incCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    homevalue_ratio_pivot_df, joined_pivot_df.County==homevalue_ratio_pivot_df.hvalCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    eth_ratio_pivot_df, joined_pivot_df.County==eth_ratio_pivot_df.ethCounty,\n    \"inner\"\n)\njoined_pivot_df = joined_pivot_df.join(\n    turnout_df, joined_pivot_df.County==turnout_df.toutCounty,\n    \"inner\"\n)\n\n# drop additional county columns\njoined_pivot_df = joined_pivot_df.drop(\n    \"ageCounty\", \"eduCounty\", \"incCounty\", \"hvalCounty\", \"ethCounty\",\"toutCounty\"\n)\n\njoined_pivot_df.printSchema()"}, {"cell_type": "code", "execution_count": 36, "id": "91bdc132-2444-44ae-a15b-53c7032dc3b6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/21 04:04:41 WARN org.apache.spark.ml.tree.impl.DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 12 (= number of training instances)\n[Stage 426:================================================>        (6 + 1) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE on the test data: 4.831580141803163\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "joined_pivot_df = joined_pivot_df.na.fill(value=0)\n# Create vector assembler to combine all features\nassembler = VectorAssembler(\n    inputCols=joined_pivot_df.schema.names[1:-1],\n    outputCol=\"features\"\n)\n# Create random forest regressor\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"G08Turnout\")\n\n# Create a pipeline for all transformations and the model\npipeline = Pipeline(stages=[assembler, rf])\n\n# Split the data into training and testing sets\n(train_data, test_data) = joined_pivot_df.randomSplit([0.7, 0.3], seed=100)\n\n# Fit the pipeline to the training data\nmodel = pipeline.fit(train_data)\n\n# Make predictions on the testing data\npredictions = model.transform(test_data)\n\n# Evaluate the performance of the model on the test data\n\nevaluator = RegressionEvaluator(\n    labelCol=\"G08Turnout\", predictionCol=\"prediction\", metricName=\"rmse\"\n)\nrmse = evaluator.evaluate(predictions)\n\nprint(f\"RMSE on the test data: {rmse}\")"}, {"cell_type": "code", "execution_count": null, "id": "656878cd-4119-4fde-aef2-88938ade6474", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}